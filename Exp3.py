# -*- coding: utf-8 -*-
"""
Exp3_Robustness_BER_Parallel.py
å®éªŒ3ï¼šæŠ—å¹²æ‰°é²æ£’æ€§æµ‹è¯• (BER Sensitivity Test) - å¤šè¿›ç¨‹å¹¶è¡Œç‰ˆ

ã€ä¿®æ”¹è¯´æ˜ã€‘
1. æ–°å¢ Goodput (æœ‰æ•ˆååç‡) æŒ‡æ ‡è®¡ç®—ã€‚
   å…¬å¼: Goodput = (Total_Tags - FP - FN) / Time_in_Seconds
2. ä¿æŒåŸæœ‰ FP/FN/Reliability è®¡ç®—é€»è¾‘ä¸å˜ã€‚
"""

import time
import logging
import random
import os
import concurrent.futures
import multiprocessing
from typing import List, Dict, Any, Set, Tuple

# --- å¯¼å…¥æ ¸å¿ƒç»„ä»¶ ---
from framework import (
    run_high_fidelity_simulation, 
    SimulationConfig, 
    Tag
)
from Algorithm_Config import ALGORITHM_LIBRARY, ALGORITHMS_TO_TEST
from Tool import SimulationAnalytics

# --- å®éªŒé…ç½® ---
# 1. è¯¯ç ç‡æµ‹è¯•èŒƒå›´
BER_RANGE = []
INDEX = 0.00
while INDEX <= 0.1:
    BER_RANGE.append(INDEX)
    INDEX += 0.005

# 2. å›ºå®šå‚æ•°
FIXED_TOTAL_TAGS = 500      # å›ºå®šæ ‡ç­¾æ•°é‡
FIXED_MISSING_RATE = 0.5    # å›ºå®šç¼ºå¤±ç‡
REPEAT_TIMES = 40           # é‡å¤æ¬¡æ•°

# 3. ç³»ç»Ÿé…ç½®
MAX_WORKERS = max(1, os.cpu_count() - 2) 
OUTPUT_DIR = "Results_Exp3_BER"

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger("Exp3_Main")
logging.getLogger('framework').setLevel(logging.WARNING)

def generate_standard_scenario(total_tags: int, missing_rate: float, run_seed: int) -> List[Tag]:
    """ç”Ÿæˆæ ‡å‡†æµ‹è¯•åœºæ™¯ (ç¡®å®šæ€§ç”Ÿæˆ)"""
    tags = []
    num_missing = int(total_tags * missing_rate)
    base_id_int = 0xE200001D4500000000000000
    
    for i in range(total_tags):
        epc_int = base_id_int + i
        epc_hex = format(epc_int, '024X')
        tags.append(Tag(epc=epc_hex, is_present=True))
        
    rng = random.Random(run_seed) 
    rng.shuffle(tags)
    # æ ‡è®°å‰ num_missing ä¸ªä¸ºç¼ºå¤±
    for i in range(num_missing):
        tags[i].is_present = False
        
    return tags

def calculate_accuracy_metrics(
    algo_instance: Any, 
    scenario_tags: List[Tag]
) -> Dict[str, float]:
    """
    ã€é˜…å·ç³»ç»Ÿã€‘è®¡ç®— FP, FN, Reliability
    """
    # 1. è·å–ç®—æ³•åˆ¤å®šç»“æœ (Predicted)
    pred_present, pred_missing = algo_instance.get_results()
    pred_present = set(pred_present)
    pred_missing = set(pred_missing)
    
    # 2. è·å–çœŸå€¼ (Ground Truth)
    actual_present = {t.epc for t in scenario_tags if t.is_present}
    actual_missing = {t.epc for t in scenario_tags if not t.is_present}
    
    # 3. è®¡ç®—æŒ‡æ ‡
    # FP (False Positive): ç®—æ³•è¯¯æŠ¥ç¼ºå¤± (å®é™…ä¸Šåœ¨åœº)
    fp_set = pred_missing.intersection(actual_present)
    
    # FN (False Negative): ç®—æ³•æ¼æŠ¥ç¼ºå¤± (è¯¯åˆ¤ä¸ºåœ¨åœº)
    fn_set = pred_present.intersection(actual_missing)
    
    fp_count = len(fp_set)
    fn_count = len(fn_set)
    total_tags = len(scenario_tags)
    
    # å¯é æ€§ (Reliability)
    reliability = 1.0 - ((fp_count + fn_count) / total_tags) if total_tags > 0 else 0.0
    
    return {
        'FP': float(fp_count),
        'FN': float(fn_count),
        'Reliability': reliability
    }

def single_experiment_task(task_params: Dict) -> Dict:
    """Worker è¿›ç¨‹å‡½æ•°"""
    ber_value = task_params['ber']
    run_idx = task_params['run_idx']
    algo_names = task_params['algo_names']
    n_tags = task_params['n_tags'] 
    
    output = {
        'results': [],
        'errors': []
    }
    
    try:
        # 1. ç”Ÿæˆåœºæ™¯
        scenario_tags = generate_standard_scenario(n_tags, FIXED_MISSING_RATE, run_seed=run_idx)
        
        for algo_name in algo_names:
            if algo_name not in ALGORITHM_LIBRARY:
                continue
                
            try:
                algo_conf = ALGORITHM_LIBRARY[algo_name]
                algo_class = algo_conf['class']
                algo_params = algo_conf.get('params', {})
                
                # B. é…ç½®ä»¿çœŸç¯å¢ƒ (å¼€å¯å™ªå£°)
                sim_config = SimulationConfig(
                    TOTAL_TAGS=n_tags,
                    MISSING_RATE=FIXED_MISSING_RATE,
                    ENABLE_ENERGY_TRACKING=True,
                    ENABLE_NOISE=True,           
                    BIT_ERROR_RATE=ber_value     
                )
                
                # C. åˆå§‹åŒ–
                algo_instance = algo_class(**algo_params)
                algo_instance.initialize(scenario_tags)
                
                # D. è¿è¡Œç‰©ç†ä»¿çœŸ (è·å¾—å¼€é”€æŒ‡æ ‡)
                start_cpu = time.time()
                stats = run_high_fidelity_simulation(algo_instance, sim_config, scenario_tags)
                cpu_duration = time.time() - start_cpu
                
                # E. ã€æ ¸å¿ƒä¿®å¤ã€‘é˜…å·ç¯èŠ‚ (è·å¾—å‡†ç¡®ç‡æŒ‡æ ‡)
                accuracy_metrics = calculate_accuracy_metrics(algo_instance, scenario_tags)
                
                # --- [æ–°å¢] è®¡ç®— Goodput ---
                time_s = stats['total_time_us'] / 1e6
                # æœ‰æ•ˆè¯†åˆ«æ•° = æ€»æ•° - é”™è¯¯æ•°(FP+FN)
                n_errors = accuracy_metrics['FP'] + accuracy_metrics['FN']
                n_correct = n_tags - n_errors
                
                # Goodput (tags/s)
                goodput = n_correct / time_s if time_s > 0 else 0.0
                accuracy_metrics['Goodput'] = goodput
                # -------------------------
                
                # F. åˆå¹¶æŒ‡æ ‡
                full_stats = {**stats, **accuracy_metrics}
                
                # G. è®°å½•
                output['results'].append({
                    'algorithm_name': algo_name,
                    'run_id': run_idx,
                    'sim_config': {
                        'TOTAL_TAGS': n_tags, 
                        'BIT_ERROR_RATE': ber_value, # Xè½´
                        'MISSING_RATE': FIXED_MISSING_RATE
                    },
                    'stats': full_stats, # åŒ…å« Time, Slots, FP, FN, Goodput
                    '_meta': {'cpu_time': cpu_duration}
                })
                
            except Exception as e:
                output['errors'].append(f"Algo '{algo_name}' failed at BER={ber_value}: {str(e)}")

    except Exception as e:
        output['errors'].append(f"Critical Batch Error at BER={ber_value}: {str(e)}")
        
    return output

def run_parallel_experiment():
    analytics = SimulationAnalytics()
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¯åŠ¨ Exp3: é²æ£’æ€§æµ‹è¯• (Goodput/FP/FN vs BER)")
    print(f"{'='*60}")
    print(f"âš™ï¸  CPUèµ„æº: {os.cpu_count()} æ ¸å¿ƒ | æ¿€æ´» Worker: {MAX_WORKERS}")
    print(f"ğŸ¯ ç®—æ³•åˆ—è¡¨: {ALGORITHMS_TO_TEST}")
    print(f"ğŸ“¡ BER æ¢¯åº¦: {['{:.1e}'.format(b) for b in BER_RANGE]}")
    print(f"ğŸ“Œ å›ºå®šå‚æ•°: N={FIXED_TOTAL_TAGS}, Missing={FIXED_MISSING_RATE}")
    print(f"{'='*60}\n")

    # 1. æ„å»ºä»»åŠ¡
    tasks = []
    for ber in BER_RANGE:
        for run_idx in range(REPEAT_TIMES):
            tasks.append({
                'ber': ber,
                'n_tags': FIXED_TOTAL_TAGS,
                'run_idx': run_idx,
                'algo_names': ALGORITHMS_TO_TEST
            })

    # æ‰“æ•£ä»»åŠ¡
    random.shuffle(tasks)
    
    total_tasks = len(tasks)
    completed_count = 0
    start_time = time.time()
    
    print(f"â³ å·²ç”Ÿæˆ {total_tasks} ä¸ª BER æµ‹è¯•ä»»åŠ¡ï¼Œæ­£åœ¨å¹¶è¡Œæ‰§è¡Œ...")

    # 2. å¹¶è¡Œæ‰§è¡Œ
    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_task = {executor.submit(single_experiment_task, t): t for t in tasks}
        
        for future in concurrent.futures.as_completed(future_to_task):
            task_info = future_to_task[future]
            completed_count += 1
            
            try:
                data = future.result()
                
                if data['errors']:
                    for err in data['errors']:
                        logger.error(f"âŒ {err}")
                
                for record in data['results']:
                    analytics.add_run_result(
                        result_stats=record['stats'],
                        sim_config=record['sim_config'],
                        algo_name=record['algorithm_name'],
                        run_id=record['run_id']
                    )
                
                elapsed = time.time() - start_time
                progress = (completed_count / total_tasks) * 100
                bar_len = 30
                filled = int(bar_len * completed_count // total_tasks)
                bar = 'â–ˆ' * filled + '-' * (bar_len - filled)
                
                print(f"\r[{bar}] {progress:5.1f}% | "
                      f"BER={task_info['ber']:.1e} | "
                      f"ETA: {(elapsed/completed_count)*(total_tasks-completed_count):.0f}s ", 
                      end="", flush=True)

            except Exception as exc:
                logger.error(f"\nâŒ System Error: {exc}")

    print(f"\n\nâœ… å®éªŒç»“æŸ! æ€»è€—æ—¶: {time.time() - start_time:.1f}s")

    # 3. å¯¼å‡ºä¸ç»˜å›¾
    print(f"ğŸ’¾ æ•°æ®å¤„ç†ä¸­...")
    analytics.save_to_csv(x_axis_key='BIT_ERROR_RATE', output_dir=OUTPUT_DIR)
    
    try:
        print("ğŸ“ˆ æ­£åœ¨ç»˜åˆ¶å›¾è¡¨...")
        analytics.plot_results(
            x_axis_key='BIT_ERROR_RATE', 
            algorithm_library=ALGORITHM_LIBRARY,
            save_path=f"{OUTPUT_DIR}/Exp3_Robustness_Summary.png"
        )
        print(f"ğŸ‰ ç»“æœå·²ä¿å­˜è‡³ {OUTPUT_DIR}/")
    except Exception as e:
        logger.error(f"âš ï¸ ç»˜å›¾å¤±è´¥: {e}")

if __name__ == "__main__":
    multiprocessing.freeze_support()
    run_parallel_experiment()