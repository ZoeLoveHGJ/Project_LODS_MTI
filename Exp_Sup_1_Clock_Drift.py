# -*- coding: utf-8 -*-
"""
Exp_Sup_1.py
è¡¥å……å®éªŒä¸€ï¼šæ—¶é’Ÿæ¼‚ç§»å‹åŠ›æµ‹è¯• (Clock Drift Tolerance Stress Test)
ç›®æ ‡ï¼š
1. éªŒè¯ç›¸å¹²çº¦æŸç†è®ºï¼šè¯æ˜ Fixed-128 (çº¢çº¿) åœ¨æ¼‚ç§» > 15% æ—¶æ€§èƒ½å´©å¡Œã€‚
2. éªŒè¯å®‰å…¨è£•é‡ï¼šè¯æ˜ Adaptive (è“çº¿) åˆ©ç”¨è‡ªé€‚åº”æœºåˆ¶èƒ½å®¹å¿æ›´é«˜çš„æ¼‚ç§»ã€‚
"""

import logging
import random
import os
import concurrent.futures
import multiprocessing
import pandas as pd
from typing import List, Dict, Any

# --- å¯¼å…¥æ ¸å¿ƒç»„ä»¶ ---
from framework import (
    run_high_fidelity_simulation, 
    SimulationConfig, 
    Tag,
    SlotResult,
    ReaderCommand,
    PacketType
)
from Tool import SimulationAnalytics

# --- å¯¼å…¥ç®—æ³• ---
from lods_mti_algo import LODS_MTI_Algorithm         # è“çº¿ (Adaptive)
from lods_mti_sup_algo import LODS_MTI_Sup_Algo      # çº¢çº¿ (Fixed-128 Stress Test)

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger("Exp_Sup_1")

# =========================================================
# ğŸ§ª å®éªŒé…ç½®
# =========================================================
TAG_COUNT = 1000
MISSING_RATE = 0.5  # å›ºå®šç¼ºå¤±ç‡ 0.5 (æœ€éš¾åœºæ™¯)

# Drift List: 0.00 -> 0.20 (0% -> 20%)
DRIFT_LIST = []
idx = 0.00
while idx <= 0.005001:
    DRIFT_LIST.append(idx)
    idx += 0.0005

REPEAT = 40
OUTPUT_DIR = "Results_Exp_Sup_1"
MAX_WORKERS = max(1, os.cpu_count() - 2) 

def run_task(task_params: Dict[str, Any]) -> Dict[str, Any]:
    """
    å•ä¸ªå®éªŒä»»åŠ¡
    """
    # è§£åŒ…å‚æ•°
    drift_rate = task_params['drift_rate']
    run_id = task_params['run_id']
    algo_type = task_params['algo_type']
    
    # 1. ç”Ÿæˆåœºæ™¯ (Seed ç»‘å®š run_id)
    # ä¿æŒå®éªŒçš„å¯é‡å¤æ€§ï¼Œä½¿å¾—çº¢è“ä¸¤çº¿åœ¨é¢å¯¹åŒä¸€ç»„æ ‡ç­¾åˆ†å¸ƒæ—¶è¿›è¡Œ PK
    tags = [Tag(format(0xE2000000 + i, '024X')) for i in range(TAG_COUNT)]
    rng = random.Random(run_id) 
    rng.shuffle(tags)
    
    # æ¨¡æ‹Ÿ 50% ç¼ºå¤± (åˆ¶é€ é«˜ä¸ç¡®å®šæ€§)
    missing_count = int(TAG_COUNT * MISSING_RATE)
    for i in range(missing_count): 
        tags[i].is_present = False
    
    # 2. å®ä¾‹åŒ–ç®—æ³•
    if algo_type == 'adaptive':
        # è“çº¿: å¼€å¯è‡ªé€‚åº” (Adaptive Mode)
        # é¢„æœŸè¡Œä¸º: é‡åˆ°æ¼‚ç§»å¯¼è‡´è¯¯ç ä¸Šå‡æ—¶ï¼Œè‡ªåŠ¨é™é€Ÿä¿å¯é æ€§
        algo = LODS_MTI_Algorithm(is_adaptive=True, target_rho=4) 
        label = "LODS-MTI (Adaptive)"
    elif algo_type == 'fixed_128':
        # çº¢çº¿: å‹åŠ›æµ‹è¯•ä¸“ç”¨ (Fixed-128)
        # é¢„æœŸè¡Œä¸º: æ­»æ¿åœ°åšæŒ K=128ï¼Œç›´åˆ°æ¼‚ç§»å¯¼è‡´åŒæ­¥ä¸¢å¤±
        algo = LODS_MTI_Sup_Algo() # é»˜è®¤å‚æ•°å³ä¸º fixed 128
        label = "LODS-Fixed-128 (Stress)"
    else:
        raise ValueError(f"Unknown algo_type: {algo_type}")

    algo.initialize(tags)
    
    # 3. é…ç½®ç¯å¢ƒ (æ³¨å…¥æ—¶é’Ÿæ¼‚ç§»)
    cfg = SimulationConfig(
        TOTAL_TAGS=TAG_COUNT,
        ENABLE_NOISE=True,       # å¼€å¯ç‰©ç†å±‚æ£€æŸ¥
        packet_error_rate=0.0,   # å…³é—­éšæœºä¸¢åŒ…ï¼Œèšç„¦æ¼‚ç§»
        BIT_ERROR_RATE=0.0,      # å…³é—­éšæœºè¯¯ç ï¼Œèšç„¦æ¼‚ç§»
        CLOCK_DRIFT_RATE=drift_rate # <--- æ ¸å¿ƒå˜é‡
    )
    
    # 4. è¿è¡Œä»¿çœŸ
    stats = run_high_fidelity_simulation(algo, cfg, tags)
    
    # 5. è®¡ç®—æŒ‡æ ‡
    # (1) Reliability / Recall
    present_gt = {t.epc for t in tags if t.is_present}
    found_present, _ = algo.get_results()
    tp = len(found_present.intersection(present_gt))
    recall = tp / len(present_gt) if present_gt else 0
    
    # (2) Goodput (Effective Throughput)
    # Tool.py è®¡ç®—çš„æ˜¯ throughput (Total / Time), è¿™é‡Œæˆ‘ä»¬è®¡ç®— Goodput (Correct / Time)
    # stats['total_time_us'] ç”± framework è¿”å›
    total_time_s = stats['total_time_us'] / 1e6
    goodput = tp / total_time_s if total_time_s > 0 else 0
    
    # 6. æ•°æ®å°è£…
    # Tool.py ä¼šè‡ªåŠ¨æå– stats ä¸­çš„æ•°å€¼åˆ—è¿›è¡Œå¹³å‡å’Œæ‹†åˆ†
    stats['Recall'] = recall
    stats['Goodput'] = goodput
    stats['Drift_Percent'] = drift_rate * 100
    
    return {
        "status": "success",
        "stats": stats,
        "sim_config": {"TOTAL_TAGS": TAG_COUNT, "Drift_Rate": drift_rate},
        "algorithm_name": label,
        "run_id": run_id
    }

if __name__ == "__main__":
    multiprocessing.freeze_support()
    
    # 1. åˆ›å»ºç›®å½•
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"ğŸ“‚ åˆ›å»ºç›®å½•: {OUTPUT_DIR}")
        
    print(f"ğŸš€ å¯åŠ¨ Exp_Sup_1: æ—¶é’Ÿæ¼‚ç§»å‹åŠ›æµ‹è¯• (Drift Stress)")
    print(f"ğŸ¯ ç›®æ ‡: éªŒè¯ç›¸å¹²çº¦æŸç†è®ºè¾¹ç•Œä¸ç³»ç»Ÿå®‰å…¨è£•é‡")
    print(f"âš™ï¸  Workers={MAX_WORKERS}, Repeat={REPEAT}, Drift_Range=[0%, 20%]")
    
    analytics = SimulationAnalytics()
    
    # 2. æ„å»ºä»»åŠ¡
    tasks = []
    for drift in DRIFT_LIST:
        for r in range(REPEAT):
            # å¯¹ç…§ç»„ 1: è“çº¿ (Adaptive)
            tasks.append({'drift_rate': drift, 'run_id': r, 'algo_type': 'adaptive'})
            # å¯¹ç…§ç»„ 2: çº¢çº¿ (Fixed-128 Stress)
            tasks.append({'drift_rate': drift, 'run_id': r, 'algo_type': 'fixed_128'})
            
    total_tasks = len(tasks)
    print(f"ğŸ“‹ ä»»åŠ¡è£…è½½å®Œæ¯•: {total_tasks} ä¸ªå­ä»»åŠ¡")

    # 3. å¹¶è¡Œæ‰§è¡Œ
    results_collected = 0
    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(run_task, t) for t in tasks]
        
        for future in concurrent.futures.as_completed(futures):
            try:
                res = future.result()
                results_collected += 1
                
                analytics.add_run_result(
                    result_stats=res['stats'],
                    sim_config=res['sim_config'],
                    algo_name=res['algorithm_name'],
                    run_id=res['run_id']
                )
                
                # è¿›åº¦æ¡
                if results_collected % 10 == 0 or results_collected == total_tasks:
                    progress = results_collected / total_tasks
                    print(f"\rğŸš€ è¿›åº¦: {progress:.1%} ({results_collected}/{total_tasks})", end="")
                
            except Exception as e:
                logger.error(f"âŒ Error: {e}")

    print("\nâœ… ä»¿çœŸç»“æŸã€‚æ­£åœ¨ç”Ÿæˆæ•°æ®æ–‡ä»¶...")
    
    # 4. ä¿å­˜æ•°æ®
    # å°†æŒ‰ç…§ 'Drift_Rate' ä¸º X è½´æ‹†åˆ†æ–‡ä»¶
    # ç»“æœå°†ç”Ÿæˆ: raw_Recall.csv, raw_Goodput.csv ç­‰
    analytics.save_to_csv(x_axis_key='Drift_Rate', output_dir=OUTPUT_DIR)
    
    print(f"ğŸ’¾ æ•°æ®ä¿å­˜å®Œæ¯•: {OUTPUT_DIR}/")
    print(f"   (è¯·ä½¿ç”¨ output ä¸­çš„ raw_Recall.csv å’Œ raw_Goodput.csv ç»˜åˆ¶çº¢è“å¯¹æ¯”å›¾)")