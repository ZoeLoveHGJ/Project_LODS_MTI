# -*- coding: utf-8 -*-
"""
Exp1_Efficiency_Parallel.py
å®éªŒ1ï¼šç³»ç»Ÿæ•ˆç‡ä¸å¯æ‰©å±•æ€§æµ‹è¯• (å¤šè¿›ç¨‹å¹¶è¡ŒåŠ é€Ÿç‰ˆ - Fixed)

ã€ä¿®å¤æ—¥å¿—ã€‘
1. [Fix] å¢åŠ  Task Shufflingï¼Œè§£å†³å°¾éƒ¨ä»»åŠ¡è¿‡é‡å¯¼è‡´çš„è¿›åº¦æ¡â€œå¡æ­»â€å‡è±¡ã€‚
2. [Fix] ç§»é™¤å­è¿›ç¨‹å†…éƒ¨ printï¼Œé¿å…å¤šè¿›ç¨‹ç®¡é“é˜»å¡ (Pipe Blocking)ã€‚
3. [Opt] ä¼˜åŒ–è¿›åº¦ä¼°ç®—ç®—æ³•ï¼Œæä¾›æ›´å‡†ç¡®çš„å‰©ä½™æ—¶é—´é¢„æµ‹ã€‚
"""

import time
import logging
import random
import os
import concurrent.futures
import multiprocessing
from typing import List, Dict, Any

# --- å¯¼å…¥æ ¸å¿ƒç»„ä»¶ ---
from framework import (
    run_high_fidelity_simulation, 
    SimulationConfig, 
    Tag
)
from Algorithm_Config import ALGORITHM_LIBRARY, ALGORITHMS_TO_TEST
from Tool import SimulationAnalytics

# --- å®éªŒé…ç½® ---
TAG_COUNTS = range(1000, 10001, 1000)  # [100, 150, ... 1000]
FIXED_MISSING_RATE = 0.5             # 10% ç¼ºå¤±ç‡
REPEAT_TIMES = 5                   # æ¯ä¸ªç‚¹é‡å¤ 20 æ¬¡
# è‡ªåŠ¨è®¡ç®— worker æ•°é‡ï¼Œä¿ç•™ 2 ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿå“åº”
MAX_WORKERS = max(1, os.cpu_count() - 2) 
OUTPUT_DIR = "Results_Exp1_Parallel_Test"

# æ—¥å¿—é…ç½® (ä»…ä¸»è¿›ç¨‹æ‰“å°)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger("Exp1_Main")
# å±è”½åº•å±‚è¯¦ç»†æ—¥å¿—ï¼Œé˜²æ­¢åˆ·å±
logging.getLogger('framework').setLevel(logging.WARNING)

def generate_standard_scenario(total_tags: int, missing_rate: float, run_seed: int) -> List[Tag]:
    """
    ç”Ÿæˆæ ‡å‡†æµ‹è¯•åœºæ™¯ (ç¡®å®šæ€§ç”Ÿæˆ)
    ä¿è¯æ¯ä¸ªç®—æ³•åœ¨ç›¸åŒçš„ run_seed ä¸‹é¢å¯¹çš„æ˜¯å®Œå…¨ä¸€æ ·çš„æ ‡ç­¾é›†åˆ
    """
    tags = []
    num_missing = int(total_tags * missing_rate)
    # å›ºå®š Base ID
    base_id_int = 0xE200001D4500000000000000
    
    for i in range(total_tags):
        epc_int = base_id_int + i
        epc_hex = format(epc_int, '024X')
        tags.append(Tag(epc=epc_hex, is_present=True))
        
    # ä½¿ç”¨ç‹¬ç«‹éšæœºæºï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨ä¸”å¯å¤ç°
    rng = random.Random(run_seed) 
    rng.shuffle(tags)
    for i in range(num_missing):
        tags[i].is_present = False
        
    return tags

def single_experiment_task(task_params: Dict) -> Dict:
    """
    ã€Worker è¿›ç¨‹å‡½æ•°ã€‘
    æ³¨æ„ï¼šæ­¤å¤„ä¸¥ç¦ä½¿ç”¨ print()ï¼Œæ‰€æœ‰ç»“æœ/é”™è¯¯å¿…é¡»é€šè¿‡ return è¿”å›ã€‚
    """
    n_tags = task_params['n_tags']
    run_idx = task_params['run_idx']
    algo_names = task_params['algo_names']
    
    # ç»“æœå®¹å™¨
    output = {
        'results': [],
        'errors': []
    }
    
    try:
        # 1. ç”Ÿæˆåœºæ™¯ (æœ¬åœ°è®¡ç®—ï¼Œå‡å°‘è·¨è¿›ç¨‹é€šä¿¡å¼€é”€)
        scenario_tags = generate_standard_scenario(n_tags, FIXED_MISSING_RATE, run_seed=run_idx)
        
        for algo_name in algo_names:
            if algo_name not in ALGORITHM_LIBRARY:
                continue
                
            try:
                # A. å®ä¾‹åŒ–é…ç½®
                algo_conf = ALGORITHM_LIBRARY[algo_name]
                algo_class = algo_conf['class']
                algo_params = algo_conf.get('params', {})
                
                # B. é…ç½®ä»¿çœŸç¯å¢ƒ (Exp1 é€šå¸¸ä¸ºç†æƒ³ç¯å¢ƒï¼Œæ— å™ªå£°)
                sim_config = SimulationConfig(
                    TOTAL_TAGS=n_tags,
                    MISSING_RATE=FIXED_MISSING_RATE,
                    ENABLE_ENERGY_TRACKING=True,
                    ENABLE_NOISE=False  # Exp1 ä¾§é‡æ•ˆç‡ï¼Œé€šå¸¸å…³é—­å™ªå£°
                )
                
                # C. åˆå§‹åŒ–ç®—æ³•
                # å¿…é¡»æ¯æ¬¡é‡æ–°å®ä¾‹åŒ–ï¼Œæ¸…é™¤å†…éƒ¨çŠ¶æ€
                algo_instance = algo_class(**algo_params)
                algo_instance.initialize(scenario_tags)
                
                # D. è¿è¡Œä»¿çœŸ
                start_cpu = time.time()
                stats = run_high_fidelity_simulation(algo_instance, sim_config, scenario_tags)
                cpu_duration = time.time() - start_cpu
                
                # E. è®°å½•æˆåŠŸç»“æœ
                output['results'].append({
                    'algorithm_name': algo_name,
                    'run_id': run_idx,
                    'sim_config': {'TOTAL_TAGS': n_tags, 'MISSING_RATE': FIXED_MISSING_RATE},
                    'stats': stats,
                    '_meta': {'cpu_time': cpu_duration}
                })
                
            except Exception as e:
                # æ•è·å•ä¸ªç®—æ³•çš„å´©æºƒï¼Œä¸å½±å“è¯¥ Batch ä¸­å…¶ä»–ç®—æ³•
                output['errors'].append(f"Algo '{algo_name}' failed at N={n_tags}: {str(e)}")

    except Exception as e:
        # æ•è·åœºæ™¯ç”Ÿæˆç­‰ä¸¥é‡é”™è¯¯
        output['errors'].append(f"Critical Batch Error at N={n_tags}: {str(e)}")
        
    return output

def run_parallel_experiment():
    # 0. å‡†å¤‡ç»Ÿè®¡å·¥å…·
    analytics = SimulationAnalytics()
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¯åŠ¨ Exp1: æ•ˆç‡ä¸å¯æ‰©å±•æ€§æµ‹è¯• (Parallel Optimized)")
    print(f"{'='*60}")
    print(f"âš™ï¸  CPUèµ„æº: {os.cpu_count()} æ ¸å¿ƒ | æ¿€æ´» Worker: {MAX_WORKERS}")
    print(f"ğŸ¯ ç®—æ³•åˆ—è¡¨: {ALGORITHMS_TO_TEST}")
    print(f"ğŸ“Š æ ‡ç­¾æ¢¯åº¦: {len(TAG_COUNTS)} ç»„ (Max N={max(TAG_COUNTS)})")
    print(f"ğŸ”„ é‡å¤æ¬¡æ•°: {REPEAT_TIMES}")
    print(f"{'='*60}\n")

    # 1. æ„å»ºä»»åŠ¡æ± 
    tasks = []
    for n_tags in TAG_COUNTS:
        for run_idx in range(REPEAT_TIMES):
            tasks.append({
                'n_tags': n_tags,
                'run_idx': run_idx,
                'algo_names': ALGORITHMS_TO_TEST
            })

    # [æ ¸å¿ƒä¿®å¤ 1] æ‰“æ•£ä»»åŠ¡é¡ºåºï¼
    # è§£å†³â€œé•¿å°¾æ•ˆåº”â€ï¼šé¿å…æœ€åå‰©ä¸‹çš„å…¨æ˜¯å¤§è§„æ¨¡(N=1000)çš„é‡å‹ä»»åŠ¡å¯¼è‡´çœ‹èµ·æ¥åƒæ­»æœºã€‚
    random.shuffle(tasks)
    
    total_tasks = len(tasks)
    completed_count = 0
    start_time = time.time()
    
    print(f"â³ å·²ç”Ÿæˆ {total_tasks} ä¸ªå­ä»»åŠ¡ï¼Œæ­£åœ¨åˆ†å‘è‡³è¿›ç¨‹æ±  (Random Order)...")

    # 2. å¹¶è¡Œæ‰§è¡Œ
    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤ä»»åŠ¡
        future_to_task = {executor.submit(single_experiment_task, t): t for t in tasks}
        
        # å¼‚æ­¥è·å–ç»“æœ
        for future in concurrent.futures.as_completed(future_to_task):
            task_info = future_to_task[future]
            completed_count += 1
            
            try:
                # è·å– Worker è¿”å›çš„å­—å…¸
                data = future.result()
                
                # å¤„ç†é”™è¯¯æ—¥å¿— (åœ¨ä¸»è¿›ç¨‹æ‰“å°)
                if data['errors']:
                    for err in data['errors']:
                        logger.error(f"âŒ {err}")
                
                # å¤„ç†æ­£å¸¸æ•°æ®
                for record in data['results']:
                    analytics.add_run_result(
                        result_stats=record['stats'],
                        sim_config=record['sim_config'],
                        algo_name=record['algorithm_name'],
                        run_id=record['run_id']
                    )
                
                # è¿›åº¦æ¡æ˜¾ç¤º
                elapsed = time.time() - start_time
                avg_time_per_task = elapsed / completed_count
                remaining_time = avg_time_per_task * (total_tasks - completed_count)
                
                # åŠ¨æ€è¿›åº¦æ¡æ ¼å¼
                progress_percent = (completed_count / total_tasks) * 100
                bar_len = 30
                filled_len = int(bar_len * completed_count // total_tasks)
                bar = 'â–ˆ' * filled_len + '-' * (bar_len - filled_len)
                
                print(f"\r[{bar}] {progress_percent:5.1f}% | "
                      f"N={task_info['n_tags']} Done | "
                      f"ETA: {remaining_time:.0f}s ", end="", flush=True)

            except Exception as exc:
                logger.error(f"\nâŒ System Error processing task {task_info}: {exc}")

    print(f"\n\nâœ… å®éªŒç»“æŸ! æ€»è€—æ—¶: {time.time() - start_time:.1f}s")

    # 3. å¯¼å‡ºæ•°æ®ä¸ç»˜å›¾
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®è‡³ {OUTPUT_DIR}...")
    analytics.save_to_csv(x_axis_key='TOTAL_TAGS', output_dir=OUTPUT_DIR)
    
    try:
        print("ğŸ“ˆ æ­£åœ¨ç»˜åˆ¶å›¾è¡¨...")
        analytics.plot_results(
            x_axis_key='TOTAL_TAGS',
            algorithm_library=ALGORITHM_LIBRARY,
            save_path=f"{OUTPUT_DIR}/Exp1_Parallel_Summary.png"
        )
        print(f"ğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆã€‚")
    except Exception as e:
        logger.error(f"âš ï¸ ç»˜å›¾æ¨¡å—æŠ¥é”™ (æ£€æŸ¥ Matplotli1b ç¯å¢ƒ): {e}")

if __name__ == "__main__":
    # Windows å¿…é¡»ä¿ç•™æ­¤ä¿æŠ¤å—
    multiprocessing.freeze_support()
    run_parallel_experiment()